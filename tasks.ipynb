{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from datetime import timedelta, date\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a list of dates that takes non public holiday and weekend days (according to https://www.geovictoria.com/mx/recursos-humanos/dias-no-laborales/ and https://www.gob.mx/cenace/articulos/cenace-publica-sus-dias-inhabiles-para-2022?idiom=es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daterange(date1, date2):\n",
    "    for n in range(int ((date2 - date1).days)+1):\n",
    "        yield date1 + timedelta(n)\n",
    "\n",
    "def create_urls(start_date,end_date):\n",
    "    # taking care of public holidays\n",
    "    public_holidays = ['2021-01-01','2021-02-01','2021-03-15','2021-04-01','2021-04-02','2021-05-05','2021-09-16-','2021-10-12','2021-11-02',\n",
    "                   '2021-11-15','2022-01-01','2022-02-07','2022-03-21','2022-04-14','2022-04-15']\n",
    "\n",
    "    labor_days = []\n",
    "\n",
    "    weekdays = [5,6]\n",
    "    for dt in daterange(start_date, end_date):\n",
    "        if (dt.weekday() not in weekdays) and (str(dt) not in public_holidays):\n",
    "            labor_days.append(dt.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "    urls_list = []\n",
    "\n",
    "    for date in labor_days:\n",
    "\n",
    "        day = date.split('-')[2].replace('0','')\n",
    "        month = date.split('-')[1]\n",
    "        year = date.split('-')[0]\n",
    "        urls_list.append(f'http://www.economia-sniim.gob.mx/Consolidados.asp?prod=&punto=100&edo=&dqdia={day}&dqmes={month}&dqanio={year}&aqdia={day}&aqmes={month}&aqanio={year}')\n",
    "    \n",
    "    return urls_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return the table with the most table data cells\n",
    "def max_len_table(x):\n",
    "    max=0\n",
    "    for i in range(len(x)):\n",
    "        current_len = len(x[i])\n",
    "        if current_len > max:\n",
    "            max = current_len\n",
    "            max_index = i\n",
    "    \n",
    "    return x[max_index].find_all('td')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return the start and stop index\n",
    "def start_stop(x):\n",
    "    for i in range(len(x)):\n",
    "        if START_KEYWORD in ''.join(x[i].findAll(text = True)):\n",
    "            ini = i+1\n",
    "        else:\n",
    "            pass\n",
    "        if STOP_KEYWORD_1 in ''.join(x[i].findAll(text = True)) or STOP_KEYWORD_2 in ''.join(x[i].findAll(text = True)):\n",
    "            fin = i\n",
    "            break\n",
    "    return ini,fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean product name tags text\n",
    "def clean_string(text):\n",
    "    return text.replace('\\n','').replace('\\xa0','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keywords to return start and finish indexes\n",
    "START_KEYWORD = 'DistribOrig'\n",
    "STOP_KEYWORD_1 = 'Granos y Semillas'\n",
    "STOP_KEYWORD_2 = 'Flores'\n",
    "\n",
    "# Dictionary keys\n",
    "KEYS_LIST = ['product','min_price','max_price','avg_price','origin','distr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    start_dt = date(2021,1,1)\n",
    "    end_dt = date(2022,7,31)\n",
    "    urls_list = create_urls(start_dt,end_dt)\n",
    "    dict_list = []\n",
    "\n",
    "    for item in urls_list:\n",
    "        page = requests.get(item)\n",
    "        if page.status_code != 200:\n",
    "            page.raise_for_status()\n",
    "        soup = BeautifulSoup(page.text,'html.parser')\n",
    "        try:\n",
    "            soup.find('p').getText()\n",
    "        except:\n",
    "            print('Current page contains information.')\n",
    "        else:\n",
    "            print('Current page does not contain information.')\n",
    "            continue\n",
    "        tables = soup.find_all('table')\n",
    "        mt = max_len_table(tables)\n",
    "        start,stop = start_stop(mt)\n",
    "\n",
    "        dummy_list = []\n",
    "        for i in range(start,stop):\n",
    "            dummy_list.append(clean_string(''.join(mt[i].getText())))\n",
    "\n",
    "        dummy_dict={}\n",
    "        for i in range(0,len(dummy_list),6):\n",
    "            dummy_dict = {}\n",
    "            for j in range(6):\n",
    "                dummy_dict[KEYS_LIST[j]] = dummy_list[i+j]\n",
    "            dict_list.append(dummy_dict)\n",
    "    \n",
    "    with open('task_1.json','w') as fp:\n",
    "        json.dump(dict_list,fp,indent=2)\n",
    "        \n",
    "    return dict_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('task_1.json')\n",
    "dict_list = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict_list)\n",
    "df = df.astype({\n",
    "                'product':'string',\n",
    "                'min_price':'float',\n",
    "                'max_price':'float',\n",
    "                'avg_price':'float',\n",
    "                'origin':'string',\n",
    "                'distr':'string'\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">describe</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Acelga</th>\n",
       "      <td>354.0</td>\n",
       "      <td>10.759887</td>\n",
       "      <td>2.988453</td>\n",
       "      <td>6.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aguacate Hass</th>\n",
       "      <td>355.0</td>\n",
       "      <td>58.818310</td>\n",
       "      <td>23.103333</td>\n",
       "      <td>21.11</td>\n",
       "      <td>44.44</td>\n",
       "      <td>47.78</td>\n",
       "      <td>72.22</td>\n",
       "      <td>111.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ajo Morado</th>\n",
       "      <td>355.0</td>\n",
       "      <td>52.481690</td>\n",
       "      <td>11.644769</td>\n",
       "      <td>36.00</td>\n",
       "      <td>45.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>56.00</td>\n",
       "      <td>94.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apio</th>\n",
       "      <td>355.0</td>\n",
       "      <td>6.235690</td>\n",
       "      <td>0.758319</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.63</td>\n",
       "      <td>6.25</td>\n",
       "      <td>6.88</td>\n",
       "      <td>8.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brócoli</th>\n",
       "      <td>355.0</td>\n",
       "      <td>12.238028</td>\n",
       "      <td>3.943863</td>\n",
       "      <td>8.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>29.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uva Superior</th>\n",
       "      <td>52.0</td>\n",
       "      <td>58.197115</td>\n",
       "      <td>9.709044</td>\n",
       "      <td>43.75</td>\n",
       "      <td>50.00</td>\n",
       "      <td>56.25</td>\n",
       "      <td>68.75</td>\n",
       "      <td>71.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uva sin semilla</th>\n",
       "      <td>287.0</td>\n",
       "      <td>68.883101</td>\n",
       "      <td>9.752816</td>\n",
       "      <td>43.75</td>\n",
       "      <td>63.75</td>\n",
       "      <td>70.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>85.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zanahoria leña</th>\n",
       "      <td>355.0</td>\n",
       "      <td>2.857465</td>\n",
       "      <td>0.460250</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.20</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zanahoria mediana</th>\n",
       "      <td>355.0</td>\n",
       "      <td>5.494141</td>\n",
       "      <td>0.494913</td>\n",
       "      <td>4.41</td>\n",
       "      <td>5.13</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.74</td>\n",
       "      <td>7.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zanahoria polvo</th>\n",
       "      <td>355.0</td>\n",
       "      <td>2.780282</td>\n",
       "      <td>0.498988</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.20</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  describe                                                    \\\n",
       "                     count       mean        std    min    25%    50%    75%   \n",
       "product                                                                        \n",
       "Acelga               354.0  10.759887   2.988453   6.00   9.00  10.00  12.00   \n",
       "Aguacate Hass        355.0  58.818310  23.103333  21.11  44.44  47.78  72.22   \n",
       "Ajo Morado           355.0  52.481690  11.644769  36.00  45.00  50.00  56.00   \n",
       "Apio                 355.0   6.235690   0.758319   5.00   5.63   6.25   6.88   \n",
       "Brócoli              355.0  12.238028   3.943863   8.00  10.00  12.00  13.00   \n",
       "...                    ...        ...        ...    ...    ...    ...    ...   \n",
       "Uva Superior          52.0  58.197115   9.709044  43.75  50.00  56.25  68.75   \n",
       "Uva sin semilla      287.0  68.883101   9.752816  43.75  63.75  70.00  75.00   \n",
       "Zanahoria leña       355.0   2.857465   0.460250   1.60   2.60   2.80   3.20   \n",
       "Zanahoria mediana    355.0   5.494141   0.494913   4.41   5.13   5.33   5.74   \n",
       "Zanahoria polvo      355.0   2.780282   0.498988   1.80   2.40   2.80   3.20   \n",
       "\n",
       "                           \n",
       "                      max  \n",
       "product                    \n",
       "Acelga              20.00  \n",
       "Aguacate Hass      111.11  \n",
       "Ajo Morado          94.00  \n",
       "Apio                 8.13  \n",
       "Brócoli             29.00  \n",
       "...                   ...  \n",
       "Uva Superior        71.25  \n",
       "Uva sin semilla     85.00  \n",
       "Zanahoria leña       4.40  \n",
       "Zanahoria mediana    7.17  \n",
       "Zanahoria polvo      4.40  \n",
       "\n",
       "[85 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('product').agg({'describe'})['avg_price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avocado = df[df['product']=='Aguacate Hass'].reset_index(drop=True).reset_index()\n",
    "df_avocado = df_avocado.rename(columns={\"index\":\"time\"})\n",
    "df_avocado = df_avocado.drop(columns=['product','origin','distr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>min_price</th>\n",
       "      <th>max_price</th>\n",
       "      <th>avg_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18.89</td>\n",
       "      <td>23.33</td>\n",
       "      <td>21.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.00</td>\n",
       "      <td>23.33</td>\n",
       "      <td>21.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20.00</td>\n",
       "      <td>23.33</td>\n",
       "      <td>21.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>20.00</td>\n",
       "      <td>23.33</td>\n",
       "      <td>21.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>21.11</td>\n",
       "      <td>24.44</td>\n",
       "      <td>22.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>350</td>\n",
       "      <td>68.89</td>\n",
       "      <td>75.56</td>\n",
       "      <td>72.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>351</td>\n",
       "      <td>61.11</td>\n",
       "      <td>72.22</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>352</td>\n",
       "      <td>61.11</td>\n",
       "      <td>72.22</td>\n",
       "      <td>65.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>353</td>\n",
       "      <td>53.33</td>\n",
       "      <td>63.33</td>\n",
       "      <td>55.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>354</td>\n",
       "      <td>52.22</td>\n",
       "      <td>61.11</td>\n",
       "      <td>54.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>355 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     time  min_price  max_price  avg_price\n",
       "0       0      18.89      23.33      21.11\n",
       "1       1      20.00      23.33      21.11\n",
       "2       2      20.00      23.33      21.11\n",
       "3       3      20.00      23.33      21.11\n",
       "4       4      21.11      24.44      22.22\n",
       "..    ...        ...        ...        ...\n",
       "350   350      68.89      75.56      72.22\n",
       "351   351      61.11      72.22      66.67\n",
       "352   352      61.11      72.22      65.56\n",
       "353   353      53.33      63.33      55.56\n",
       "354   354      52.22      61.11      54.44\n",
       "\n",
       "[355 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avocado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func to plot metrics on train and test set\n",
    "def plot_metrics(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_'+string])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func to plot time series\n",
    "def plot_series(time, series, ylabel ,format=\"-\", start=0, end=None):\n",
    "    plt.plot(time[start:end], series[start:end], format)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func to normalize series\n",
    "def normalize_series(data,min,max):\n",
    "    data = data - min\n",
    "    data = data / max\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func to create windowed dataset\n",
    "def windowed_dataset(series, batch_size, n_past, n_future, shift=1):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(size=n_past + n_future, shift=shift, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(n_past + n_future))\n",
    "    ds = ds.map(lambda w: (w[:n_past], w[n_past:]))\n",
    "    return ds.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_2_2(N):\n",
    "    # Creating the main dataframe that we will be transforming to use in the model\n",
    "    df_avocado = df[df['product']=='Aguacate Hass'].reset_index(drop=True).reset_index()\n",
    "    df_avocado = df_avocado.rename(columns={\"index\":\"time\"})\n",
    "    df_avocado = df_avocado.drop(columns=['product','origin','distr'])\n",
    "\n",
    "    # Number of features in the dataset\n",
    "    N_FEATURES = len(df_avocado.columns)\n",
    "\n",
    "    # Normalize the data\n",
    "    data = df_avocado.values\n",
    "    data = normalize_series(data, data.min(axis=0), data.max(axis=0))\n",
    "\n",
    "    # Split the data into train and test sets. As test set is pretty important here,\n",
    "    # we will do a 50/50 split and try to create a model that generalizes well on the test set\n",
    "    SPLIT_TIME = int(len(data)*0.5)\n",
    "    x_train = data[:SPLIT_TIME]\n",
    "    x_test = data[SPLIT_TIME:]\n",
    "\n",
    "    # Small batch size hence the small amount of data\n",
    "    BATCH_SIZE = 16\n",
    "\n",
    "    # Number of past time steps based on which future observations should be predicted.\n",
    "    N_PAST = N\n",
    "\n",
    "    # Number of future time steps which are to be predicted.\n",
    "    N_FUTURE = N\n",
    "\n",
    "    # Positions from which the window slides to create a new window\n",
    "    SHIFT = 1\n",
    "\n",
    "    # Creating a callback to tune the learning rate\n",
    "    #lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch / 20))\n",
    "    # It look like the optimal learning rate was around 0.001\n",
    "\n",
    "    # Creation of windowed train and test set\n",
    "    train_set = windowed_dataset(series = x_train, batch_size = BATCH_SIZE,\n",
    "                                 n_past = N_PAST, n_future = N_FUTURE,\n",
    "                                 shift = SHIFT)\n",
    "\n",
    "    test_set = windowed_dataset(series = x_test, batch_size = BATCH_SIZE,\n",
    "                                n_past = N_PAST, n_future = N_FUTURE,\n",
    "                                shift = SHIFT)\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences = True,\n",
    "                                      input_shape = [N_PAST,N_FEATURES], batch_size = BATCH_SIZE)),\n",
    "        \n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        tf.keras.layers.Dense(30, activation='relu'),\n",
    "\n",
    "        tf.keras.layers.Dense(10, activation='relu'),\n",
    "\n",
    "        tf.keras.layers.Dense(N_FEATURES)\n",
    "\n",
    "    ])\n",
    "\n",
    "    EPOCHS = 30\n",
    "\n",
    "    model.compile(loss = tf.keras.losses.Huber(),\n",
    "                  optimizer = tf.keras.optimizers.Adam(lr = 0.001),\n",
    "                  metrics = [\"mse\",\"accuracy\"])\n",
    "    \n",
    "    history = model.fit(train_set, validation_data = test_set, epochs = EPOCHS) #callbacks = [lr_schedule]) was used to tune the learning rate\n",
    "\n",
    "    # Plotting accuracy\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plot_metrics(history, \"accuracy\")\n",
    "\n",
    "    # Plotting mse\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plot_metrics(history, \"mse\")\n",
    "\n",
    "    return model,x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With this, we now know that our learning rate should stay somewhere around 10^-2. But it is important to note that, for this case, it was trained for only four steps into the future; the further we want to predict into the future, the more likely it is for the mse to increase. Either way, the model can be tested with different N future steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>min_price</th>\n",
       "      <th>max_price</th>\n",
       "      <th>avg_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18.89</td>\n",
       "      <td>23.33</td>\n",
       "      <td>21.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.00</td>\n",
       "      <td>23.33</td>\n",
       "      <td>21.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20.00</td>\n",
       "      <td>23.33</td>\n",
       "      <td>21.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>20.00</td>\n",
       "      <td>23.33</td>\n",
       "      <td>21.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>21.11</td>\n",
       "      <td>24.44</td>\n",
       "      <td>22.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>350</td>\n",
       "      <td>68.89</td>\n",
       "      <td>75.56</td>\n",
       "      <td>72.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>351</td>\n",
       "      <td>61.11</td>\n",
       "      <td>72.22</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>352</td>\n",
       "      <td>61.11</td>\n",
       "      <td>72.22</td>\n",
       "      <td>65.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>353</td>\n",
       "      <td>53.33</td>\n",
       "      <td>63.33</td>\n",
       "      <td>55.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>354</td>\n",
       "      <td>52.22</td>\n",
       "      <td>61.11</td>\n",
       "      <td>54.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>355 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     time  min_price  max_price  avg_price\n",
       "0       0      18.89      23.33      21.11\n",
       "1       1      20.00      23.33      21.11\n",
       "2       2      20.00      23.33      21.11\n",
       "3       3      20.00      23.33      21.11\n",
       "4       4      21.11      24.44      22.22\n",
       "..    ...        ...        ...        ...\n",
       "350   350      68.89      75.56      72.22\n",
       "351   351      61.11      72.22      66.67\n",
       "352   352      61.11      72.22      65.56\n",
       "353   353      53.33      63.33      55.56\n",
       "354   354      52.22      61.11      54.44\n",
       "\n",
       "[355 rows x 4 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avocado = df[df['product']=='Aguacate Hass'].reset_index(drop=True).reset_index()\n",
    "df_avocado = df_avocado.rename(columns={\"index\":\"time\"})\n",
    "df_avocado = df_avocado.drop(columns=['product','origin','distr'])\n",
    "df_avocado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177.5"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "355/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func to normalize series\n",
    "def normalize_series(data,min,max):\n",
    "    data = data - min\n",
    "    data = data / max\n",
    "    return data\n",
    "\n",
    "def unnormalize_series(data,min,max):\n",
    "    data = data * max\n",
    "    data = data + min\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sebastian\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 70ms/step - loss: 0.0321 - mse: 0.0641 - accuracy: 0.6986 - val_loss: 0.1366 - val_mse: 0.2732 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0118 - mse: 0.0237 - accuracy: 0.6977 - val_loss: 0.0540 - val_mse: 0.1081 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0072 - mse: 0.0145 - accuracy: 0.6977 - val_loss: 0.0317 - val_mse: 0.0633 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0051 - mse: 0.0102 - accuracy: 0.6977 - val_loss: 0.0223 - val_mse: 0.0447 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0038 - mse: 0.0077 - accuracy: 0.6977 - val_loss: 0.0167 - val_mse: 0.0334 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0033 - mse: 0.0066 - accuracy: 0.6715 - val_loss: 0.0144 - val_mse: 0.0288 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0030 - mse: 0.0059 - accuracy: 0.6715 - val_loss: 0.0134 - val_mse: 0.0269 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0027 - mse: 0.0055 - accuracy: 0.6679 - val_loss: 0.0131 - val_mse: 0.0262 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0027 - mse: 0.0053 - accuracy: 0.6670 - val_loss: 0.0129 - val_mse: 0.0258 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0026 - mse: 0.0051 - accuracy: 0.6742 - val_loss: 0.0124 - val_mse: 0.0248 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0025 - mse: 0.0050 - accuracy: 0.7004 - val_loss: 0.0122 - val_mse: 0.0245 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0025 - mse: 0.0049 - accuracy: 0.7076 - val_loss: 0.0118 - val_mse: 0.0236 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0023 - mse: 0.0046 - accuracy: 0.7184 - val_loss: 0.0114 - val_mse: 0.0228 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0023 - mse: 0.0046 - accuracy: 0.7437 - val_loss: 0.0110 - val_mse: 0.0220 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0022 - mse: 0.0044 - accuracy: 0.7410 - val_loss: 0.0107 - val_mse: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0022 - mse: 0.0043 - accuracy: 0.7392 - val_loss: 0.0097 - val_mse: 0.0194 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0020 - mse: 0.0040 - accuracy: 0.7626 - val_loss: 0.0089 - val_mse: 0.0179 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0018 - mse: 0.0036 - accuracy: 0.7951 - val_loss: 0.0077 - val_mse: 0.0154 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0017 - mse: 0.0035 - accuracy: 0.7753 - val_loss: 0.0069 - val_mse: 0.0137 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0016 - mse: 0.0032 - accuracy: 0.7708 - val_loss: 0.0065 - val_mse: 0.0130 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0015 - mse: 0.0029 - accuracy: 0.7780 - val_loss: 0.0048 - val_mse: 0.0096 - val_accuracy: 0.8359\n",
      "Epoch 22/30\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0016 - mse: 0.0031 - accuracy: 0.7662 - val_loss: 0.0049 - val_mse: 0.0099 - val_accuracy: 0.7305\n",
      "Epoch 23/30\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0016 - mse: 0.0032 - accuracy: 0.7455 - val_loss: 0.0045 - val_mse: 0.0091 - val_accuracy: 0.5820\n",
      "Epoch 24/30\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0013 - mse: 0.0026 - accuracy: 0.7392 - val_loss: 0.0038 - val_mse: 0.0076 - val_accuracy: 0.9102\n",
      "Epoch 25/30\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0027 - mse: 0.0054 - accuracy: 0.6038 - val_loss: 0.0082 - val_mse: 0.0165 - val_accuracy: 0.9961\n",
      "Epoch 26/30\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0017 - mse: 0.0034 - accuracy: 0.7653 - val_loss: 0.0054 - val_mse: 0.0108 - val_accuracy: 0.6016\n",
      "Epoch 27/30\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0014 - mse: 0.0029 - accuracy: 0.6895 - val_loss: 0.0046 - val_mse: 0.0093 - val_accuracy: 0.8164\n",
      "Epoch 28/30\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0013 - mse: 0.0025 - accuracy: 0.7139 - val_loss: 0.0038 - val_mse: 0.0075 - val_accuracy: 0.8633\n",
      "Epoch 29/30\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0015 - mse: 0.0030 - accuracy: 0.6724 - val_loss: 0.0044 - val_mse: 0.0088 - val_accuracy: 0.8203\n",
      "Epoch 30/30\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0015 - mse: 0.0031 - accuracy: 0.7708 - val_loss: 0.0054 - val_mse: 0.0107 - val_accuracy: 0.5742\n"
     ]
    }
   ],
   "source": [
    "n = 4\n",
    "\n",
    "# Creating the main dataframe that we will be transforming to use in the model\n",
    "df_avocado = df[df['product']=='Aguacate Hass'].reset_index(drop=True).reset_index()\n",
    "df_avocado = df_avocado.rename(columns={\"index\":\"time\"})\n",
    "df_avocado = df_avocado.drop(columns=['product','origin','distr'])\n",
    "\n",
    "    # Number of features in the dataset\n",
    "N_FEATURES = len(df_avocado.columns)\n",
    "\n",
    "# Normalize the data\n",
    "data = df_avocado.values\n",
    "# Save values to de normalize data\n",
    "data_min,data_max = data.min(axis=0),data.max(axis=0)\n",
    "data = normalize_series(data, data.min(axis=0), data.max(axis=0))\n",
    "\n",
    "    # Split the data into train and test sets. As test set is pretty important here,\n",
    "    # we will do a 50/50 split and try to create a model that generalizes well on the test set\n",
    "SPLIT_TIME = int(len(data)*0.8)\n",
    "x_train = data[:SPLIT_TIME]\n",
    "x_test = data[SPLIT_TIME:]\n",
    "\n",
    "    # Small batch size hence the small amount of data\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "    # Number of past time steps based on which future observations should be predicted.\n",
    "N_PAST = n\n",
    "\n",
    "    # Number of future time steps which are to be predicted.\n",
    "N_FUTURE = n\n",
    "\n",
    "    # Positions from which the window slides to create a new window\n",
    "SHIFT = 1\n",
    "\n",
    "    # Creating a callback to tune the learning rate\n",
    "    #lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch / 20))\n",
    "    # It look like the optimal learning rate was around 0.001\n",
    "\n",
    "    # Creation of windowed train and test set\n",
    "train_set = windowed_dataset(series = x_train, batch_size = BATCH_SIZE,\n",
    "                                 n_past = N_PAST, n_future = N_FUTURE,\n",
    "                                 shift = SHIFT)\n",
    "\n",
    "test_set = windowed_dataset(series = x_test, batch_size = BATCH_SIZE,\n",
    "                                n_past = N_PAST, n_future = N_FUTURE,\n",
    "                                shift = SHIFT)\n",
    "    \n",
    "model = tf.keras.models.Sequential([\n",
    "\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences = True,\n",
    "                                      input_shape = [N_PAST,N_FEATURES], batch_size = BATCH_SIZE)),\n",
    "        \n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "    tf.keras.layers.Dense(30, activation='relu'),\n",
    "\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "\n",
    "    tf.keras.layers.Dense(N_FEATURES)\n",
    "\n",
    "    ])\n",
    "\n",
    "EPOCHS = 30\n",
    "\n",
    "model.compile(loss = tf.keras.losses.Huber(),\n",
    "              optimizer = tf.keras.optimizers.Adam(lr = 0.001),\n",
    "              metrics = [\"mse\",\"accuracy\"],\n",
    "              run_eagerly=True)\n",
    "    \n",
    "history = model.fit(train_set, validation_data = test_set, epochs = EPOCHS) #callbacks = [lr_schedule]) was used to tune the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>min_price</th>\n",
       "      <th>max_price</th>\n",
       "      <th>avg_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>282</td>\n",
       "      <td>78.89</td>\n",
       "      <td>85.56</td>\n",
       "      <td>82.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>283</td>\n",
       "      <td>80.00</td>\n",
       "      <td>86.67</td>\n",
       "      <td>83.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     time  min_price  max_price  avg_price\n",
       "282   282      78.89      85.56      82.22\n",
       "283   283      80.00      86.67      83.33"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# serie de training.... La vamos a utilizar para predecir los proximos N dias....\n",
    "df_avocado.iloc[282:284]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>min_price</th>\n",
       "      <th>max_price</th>\n",
       "      <th>avg_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>288</td>\n",
       "      <td>81.11</td>\n",
       "      <td>87.78</td>\n",
       "      <td>83.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>289</td>\n",
       "      <td>82.22</td>\n",
       "      <td>88.89</td>\n",
       "      <td>83.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>290</td>\n",
       "      <td>83.33</td>\n",
       "      <td>88.89</td>\n",
       "      <td>84.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>291</td>\n",
       "      <td>86.67</td>\n",
       "      <td>92.22</td>\n",
       "      <td>87.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>292</td>\n",
       "      <td>86.67</td>\n",
       "      <td>92.22</td>\n",
       "      <td>87.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     time  min_price  max_price  avg_price\n",
       "288   288      81.11      87.78      83.33\n",
       "289   289      82.22      88.89      83.33\n",
       "290   290      83.33      88.89      84.44\n",
       "291   291      86.67      92.22      87.78\n",
       "292   292      86.67      92.22      87.78"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avocado.iloc[282:293].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting N time steps into the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_data = x_train[SPLIT_TIME-2:] \n",
    "w_start_set = windowed_dataset(series = starting_data, batch_size = BATCH_SIZE,\n",
    "                               n_past = N_PAST, n_future = N_FUTURE,\n",
    "                               shift = 1)\n",
    "\n",
    "for i in range(N):\n",
    "        if i != N-1:\n",
    "            temp_pred = history.model.predict(w_start_set)\n",
    "            temp_pred = temp_pred.reshape(temp_pred.shape[0],-1)\n",
    "            temp_arr = np.vstack((starting_data[-1],temp_pred))\n",
    "            w_start_set = windowed_dataset(series = temp_arr[-2:], batch_size = BATCH_SIZE,\n",
    "                                           n_past = N_PAST, n_future = N_FUTURE,\n",
    "                                           shift = 1)\n",
    "        else:\n",
    "            future_pred = history.model.predict(w_start_set)\n",
    "            future_pred = future_pred.reshape(future_pred.shape[0],-1)\n",
    "            future_pred = unnormalize_series(future_pred,data_min,data_max)\n",
    "            print('Estimated maximum and minimum price of avocado in',N,'days:', round(future_pred[0][2],2),'$,',round(future_pred[0][1],2), '$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With this, we now know that our learning rate should stay somewhere around 10^-2. But it is important to note that, for this case, it was trained for only four steps into the future; the further we want to predict into the future, the more likely it is for the mse to increase. Either way, the model can be tested with different N future steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "823b1656cea8c6df706fabc152533cb5f899e22f4bca7bf508bdcdbf2484c2a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
